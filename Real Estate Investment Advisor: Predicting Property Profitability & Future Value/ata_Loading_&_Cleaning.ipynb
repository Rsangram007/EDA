{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c59b17fb-d39f-4481-9fcf-03189609e5aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install xgboost streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "cbbfecc0-9423-4743-8926-d0b6f8f67486",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0948a04e-6574-4f4a-a8d1-18411574cd23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./india_housing_prices.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4835acef-56a4-4e47-a7cd-b1f8d5bc4580",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 2: Basic info & missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "####################################for Duplicate Handle##########\n",
    "\n",
    "\n",
    "print(df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "38267ebe-d597-4cd3-a455-e880c5fab65a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FULL CATEGORICAL ENCODING CODE (Copy-Paste This)\n",
    "# Required columns: State, City, Locality, Property_Type, etc.\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# List of ALL categorical columns that MUST be encoded\n",
    "categorical_columns = [\n",
    "    'State',\n",
    "    'City',\n",
    "    'Locality',               # This is \"Location\"\n",
    "    'Property_Type',          # Apartment, Villa, etc.\n",
    "    'Furnished_Status',       # Unfurnished, Semi, Fully\n",
    "    'Facing',                 # North, East, etc.\n",
    "    'Owner_Type',             # Builder, Individual\n",
    "    'Availability_Status',    # Ready to Move, Under Construction\n",
    "    'Security',               # Gated, CCTV, etc.\n",
    "    'Amenities',              # Gym,Pool,... (as string)\n",
    "    'Public_Transport_Accessibility'\n",
    "]\n",
    "\n",
    "print(\"Encoding the following categorical columns:\")\n",
    "for col in categorical_columns:\n",
    "    print(f\"  → {col} : {df[col].nunique()} unique values\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b1846a7c-9659-4578-97c5-14c146cfb06d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary to save all encoders (needed later in Streamlit app)\n",
    "label_encoders = {}\n",
    "\n",
    "# Apply Label Encoding to each column\n",
    "for col in categorical_columns:\n",
    "    print(f\"Encoding {col}...\")\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # Convert to string first to avoid issues\n",
    "    df[col + '_encoded'] = le.fit_transform(df[col].astype(str))\n",
    "    \n",
    "    # Save the encoder for use in Streamlit prediction\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Show example\n",
    "print(\"\\nEncoding Done! Example:\")\n",
    "print(df[['City', 'City_encoded', 'Property_Type', 'Property_Type_encoded', 'Locality', 'Locality_encoded']].head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "2a84722f-96a8-42ab-bd69-c29e7a85354d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the encoders for Streamlit app (VERY IMPORTANT!)\n",
    "joblib.dump(label_encoders, \"./label_encoders.pkl\")\n",
    "print(\"\\nLabel Encoders saved to: ./label_encoders.pkl\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "40184f01-b30f-4614-9b9d-7fec72e3ae4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Final list of encoded column names (you will use these in model training)\n",
    "encoded_columns = [col + '_encoded' for col in categorical_columns]\n",
    "print(\"\\nUse these columns in your model:\")\n",
    "print(encoded_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3eefcb86-c135-4572-8372-7632401e7ead",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP: Create New Features + Good_Investment Label \n",
    "# =============================================================================\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 1. NEW FEATURES \n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Feature 1: Price per SqFt (most important real estate metric)\n",
    "df['Price_per_SqFt'] = df['Price_in_Lakhs'] * 100000 / df['Size_in_SqFt']\n",
    "\n",
    "# Feature 2: Age of Property\n",
    "df['Age_of_Property'] = 2025 - df['Year_Built']\n",
    "\n",
    "# Feature 3: School Density Score (0 to 10 scale)\n",
    "df['School_Density_Score'] = pd.cut(df['Nearby_Schools'],\n",
    "                                   bins=[-1, 1, 3, 6, 10],\n",
    "                                   labels=[2, 4, 7, 10]).astype(int)\n",
    "\n",
    "# Feature 4: Hospital Density Score\n",
    "df['Hospital_Density_Score'] = pd.cut(df['Nearby_Hospitals'],\n",
    "                                     bins=[-1, 0, 2, 5, 10],\n",
    "                                     labels=[2, 5, 8, 10]).astype(int)\n",
    "\n",
    "# Feature 5: Amenities Count\n",
    "amenities_keywords = ['Gym', 'Pool', 'Clubhouse', 'Park', 'Lift', 'Power Backup', 'Garden']\n",
    "df['Amenities_Count'] = df['Amenities'].apply(\n",
    "    lambda x: sum(1 for word in amenities_keywords if str(word) in str(x))\n",
    ")\n",
    "\n",
    "# Feature 6: Security Score (0 to 10)\n",
    "security_map = {'None': 0, 'CCTV': 3, 'Guard': 5, 'Gated': 7,\n",
    "                'Gated, CCTV': 8, 'Gated, Guard': 9, 'Gated, CCTV, Guard': 10}\n",
    "df['Security_Score'] = df['Security'].map(security_map).fillna(0)\n",
    "\n",
    "# Feature 7: Transport Score\n",
    "transport_map = {'Poor': 2, 'Medium': 5, 'Good': 8, 'Excellent': 10}\n",
    "df['Transport_Score'] = df['Public_Transport_Accessibility'].map(transport_map).fillna(5)\n",
    "\n",
    "# Feature 8: Is Tier-1 City?\n",
    "tier1_cities = ['Mumbai', 'Delhi', 'Bangalore', 'Hyderabad', 'Pune', 'Chennai', 'Kolkata']\n",
    "df['Is_Tier1_City'] = df['City'].isin(tier1_cities).astype(int)\n",
    "\n",
    "# Feature 9: Is New Property?\n",
    "df['Is_New_Property'] = (df['Age_of_Property'] <= 5).astype(int)\n",
    "\n",
    "# Feature 10: Is Ready to Move?\n",
    "df['Is_Ready_to_Move'] = (df['Availability_Status'] == 'Ready to Move').astype(int)\n",
    "\n",
    "print(\"New Features Created Successfully!\")\n",
    "print(df[['Price_per_SqFt', 'School_Density_Score', 'Amenities_Count', 'Security_Score', 'Is_Tier1_City']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3d8efc34-d874-4575-b0c3-0bc7f749b682",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 2. CREATE TARGET: Good_Investment (Binary 0/1) – Based on Real Domain Rules\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Rule used by top investors in India:\n",
    "# \"Good Investment\" if ALL these are true:\n",
    "# 1. Price per SqFt is ≤ 5% above city median (not overpriced)\n",
    "# 2. High growth potential (Tier-1 city OR new property OR excellent location scores)\n",
    "\n",
    "city_median = df.groupby('City')['Price_per_SqFt'].transform('median')\n",
    "\n",
    "df['Good_Investment'] = (\n",
    "    (df['Price_per_SqFt'] <= city_median * 1.05) &   # Not overpriced\n",
    "    (\n",
    "        (df['Is_Tier1_City'] == 1) |\n",
    "        (df['Is_New_Property'] == 1) |\n",
    "        (df['School_Density_Score'] >= 7) |\n",
    "        (df['Transport_Score'] >= 8) |\n",
    "        (df['Amenities_Count'] >= 3)\n",
    "    )\n",
    ").astype(int)\n",
    "\n",
    "# Show results\n",
    "print(\"\\nGood_Investment Label Created!\")\n",
    "print(df['Good_Investment'].value_counts())\n",
    "\n",
    "print(\"\\nPercentage of Good Investments:\", \n",
    "      round(df['Good_Investment'].mean() * 100, 1), \"%\")\n",
    "\n",
    "# Example: Top good investment cities\n",
    "print(\"\\nTop cities with most Good Investments:\")\n",
    "print(df[df['Good_Investment']==1]['City'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "418fd8e7-ee45-4af4-a320-415aae8ad742",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"./final_with_features_and_target.csv\", index=False)\n",
    "print(\"Saved! Ready for model training →\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6aef3d11-be17-4219-abb5-4a72fa6dcb9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: FULL EXPLORATORY DATA ANALYSIS (EDA) \n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Dataset loaded: {df.shape[0]:,} properties, {df.shape[1]} features\")\n",
    "print(\"Good Investment ratio:\", round(df['Good_Investment'].mean()*100, 1), \"%\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1–5: Price & Size Analysis\n",
    "# =============================================================================\n",
    "\n",
    "print(\"1–5: PRICE & SIZE ANALYSIS\".center(80, \"=\"))\n",
    "\n",
    "# 1. Distribution of property prices\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(df['Price_in_Lakhs'], bins=100, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Property Prices (₹ Lakhs)')\n",
    "plt.xlabel('Price in Lakhs')\n",
    "\n",
    "# 2. Distribution of property sizes\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(df['Size_in_SqFt'], bins=80, kde=True, color='salmon')\n",
    "plt.title('Distribution of Property Size (SqFt)')\n",
    "plt.xlabel('Size in SqFt')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Price per SqFt by Property Type\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x='Property_Type', y='Price_per_SqFt', data=df, palette='Set2')\n",
    "plt.title('Price per SqFt by Property Type')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# 4. Relationship: Size vs Price\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x='Size_in_SqFt', y='Price_in_Lakhs', data=df, alpha=0.6, hue='Good_Investment', palette=['red','green'])\n",
    "plt.title('Property Size vs Price (Green = Good Investment)')\n",
    "plt.legend(title='Good Investment')\n",
    "plt.show()\n",
    "\n",
    "# 5. Outliers in Price per SqFt\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.boxplot(x=df['Price_per_SqFt'])\n",
    "plt.title('Outliers: Price per SqFt')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(x=df['Size_in_SqFt'])\n",
    "plt.title('Outliers: Size in SqFt')\n",
    "plt.show()\n",
    "\n",
    "print(\"High-end properties (top 1%):\", df[df['Price_in_Lakhs'] > df['Price_in_Lakhs'].quantile(0.99)].shape[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "d3233c1e-3194-4fa5-8a75-c61f183cfe11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6–10: Location-based Analysis\n",
    "# =============================================================================\n",
    "\n",
    "print(\"6–10: LOCATION-BASED ANALYSIS\".center(80, \"=\"))\n",
    "\n",
    "# 6. Avg Price per SqFt by State\n",
    "plt.figure(figsize=(12,6))\n",
    "state_price = df.groupby('State')['Price_per_SqFt'].mean().sort_values(ascending=False).head(10)\n",
    "state_price.plot(kind='bar', color='coral')\n",
    "plt.title('Top 10 States by Avg Price per SqFt')\n",
    "plt.ylabel('Avg Price per SqFt (₹)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# 7. Avg Property Price by City (Top 15)\n",
    "plt.figure(figsize=(12,6))\n",
    "city_price = df.groupby('City')['Price_in_Lakhs'].mean().sort_values(ascending=False).head(15)\n",
    "city_price.plot(kind='bar', color='teal')\n",
    "plt.title('Top 15 Cities by Average Property Price')\n",
    "plt.ylabel('Avg Price (₹ Lakhs)')\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()\n",
    "\n",
    "# 8. Median Age by Locality (Top 20 oldest)\n",
    "plt.figure(figsize=(10,6))\n",
    "df.groupby('Locality')['Age_of_Property'].median().sort_values(ascending=False).head(20).plot(kind='barh', color='purple')\n",
    "plt.title('Top 20 Oldest Localities (Median Age)')\n",
    "plt.xlabel('Median Age of Property')\n",
    "plt.show()\n",
    "\n",
    "# 9. BHK Distribution Across Top Cities\n",
    "top_cities = df['City'].value_counts().head(8).index\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(data=df[df['City'].isin(top_cities)], x='City', hue='BHK', palette='Set3')\n",
    "plt.title('BHK Distribution Across Top Cities')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='BHK')\n",
    "plt.show()\n",
    "\n",
    "# 10. Price Trends in Top 5 Most Expensive Localities\n",
    "top_localities = df.groupby('Locality')['Price_per_SqFt'].median().sort_values(ascending=False).head(5).index\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=df[df['Locality'].isin(top_localities)], x='Locality', y='Price_per_SqFt')\n",
    "plt.title('Price per SqFt in Top 5 Most Expensive Localities')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "7e36b412-8590-4915-8af4-58730ba8f993",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 11–15: Feature Relationships & Correlation\n",
    "# =============================================================================\n",
    "\n",
    "print(\"11–15: CORRELATION & RELATIONSHIPS\".center(80, \"=\"))\n",
    "\n",
    "# 11. Correlation Heatmap\n",
    "plt.figure(figsize=(14,10))\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "corr = df[numeric_cols].corr()\n",
    "sns.heatmap(corr, cmap='coolwarm', center=0, annot=False, square=True)\n",
    "plt.title('Correlation Matrix of All Numeric Features')\n",
    "plt.show()\n",
    "\n",
    "# 12–13. Schools & Hospitals vs Price per SqFt\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.scatterplot(x='Nearby_Schools', y='Price_per_SqFt', data=df, alpha=0.5)\n",
    "plt.title('Nearby Schools vs Price per SqFt')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.scatterplot(x='Nearby_Hospitals', y='Price_per_SqFt', data=df, alpha=0.5, color='orange')\n",
    "plt.title('Nearby Hospitals vs Price per SqFt')\n",
    "plt.show()\n",
    "\n",
    "# 14. Price by Furnished Status\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x='Furnished_Status', y='Price_in_Lakhs', data=df)\n",
    "plt.title('Property Price by Furnishing Status')\n",
    "plt.show()\n",
    "\n",
    "# 15. Price per SqFt by Facing Direction\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x='Facing', y='Price_per_SqFt', data=df, palette='pastel')\n",
    "plt.title('Price per SqFt by Property Facing Direction')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "7c5e5484-554d-4670-97cc-06086ff89b11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 16–20: Investment, Amenities & Ownership Analysis\n",
    "# =============================================================================\n",
    "\n",
    "print(\"16–20: INVESTMENT & AMENITIES INSIGHTS\".center(80, \"=\"))\n",
    "\n",
    "# 16. Owner Type Distribution\n",
    "plt.figure(figsize=(8,5))\n",
    "df['Owner_Type'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Properties by Owner Type')\n",
    "plt.ylabel('')\n",
    "plt.show()\n",
    "\n",
    "# 17. Availability Status\n",
    "plt.figure(figsize=(8,5))\n",
    "df['Availability_Status'].value_counts().plot(kind='bar', color='gold')\n",
    "plt.title('Properties by Availability Status')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# 18. Parking Space vs Price\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x='Parking_Space', y='Price_in_Lakhs', data=df)\n",
    "plt.title('Does More Parking = Higher Price?')\n",
    "plt.show()\n",
    "\n",
    "# 19. Amenities Count vs Price per SqFt\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x='Amenities_Count', y='Price_per_SqFt', data=df)\n",
    "plt.title('More Amenities → Higher Price per SqFt')\n",
    "plt.show()\n",
    "\n",
    "# 20. Public Transport vs Good Investment\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x='Public_Transport_Accessibility', hue='Good_Investment', data=df, palette=['#ff9999','#66b3ff'])\n",
    "plt.title('Transport Access → Good Investment?')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "transport_investment = df.groupby('Public_Transport_Accessibility')['Good_Investment'].mean().sort_values(ascending=False)\n",
    "transport_investment.plot(kind='bar', color='green')\n",
    "plt.title('% of Good Investments by Transport Access')\n",
    "plt.ylabel('% Good Investment')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"EDA COMPLETED –  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "fd7b9cd1-9051-44f7-8411-d8f56d27914a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save EDA insights summary\n",
    "insights = {\n",
    "    \"Total Properties\": len(df),\n",
    "    \"Good Investment %\": round(df['Good_Investment'].mean()*100, 1),\n",
    "    \"Most Expensive City\": df.groupby('City')['Price_in_Lakhs'].mean().idxmax(),\n",
    "    \"Cheapest City\": df.groupby('City')['Price_in_Lakhs'].mean().idxmin(),\n",
    "    \"Best for Investment\": df[df['Good_Investment']==1]['City'].mode()[0]\n",
    "}\n",
    "\n",
    "# pd.Series(insights).to_csv(\"./eda_summary_insights.csv\")\n",
    "print(\"EDA Summary Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "2b8dc6b1-9fac-497d-8c43-21b01cc36e09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"./final_with_features_and_target.csv\")\n",
    "\n",
    "# === CREATE REGRESSION TARGET: Future_Price_5Y ===\n",
    "# Realistic 5-year appreciation based on city tier + property type\n",
    "growth_rate = {\n",
    "    'Mumbai': 0.10, 'Delhi': 0.09, 'Bangalore': 0.09, 'Pune': 0.085,\n",
    "    'Hyderabad': 0.08, 'Chennai': 0.07, 'Kolkata': 0.06\n",
    "}\n",
    "df['growth_rate'] = df['City'].map(growth_rate).fillna(0.07)\n",
    "df['Future_Price_5Y'] = df['Price_in_Lakhs'] * (1 + df['growth_rate'])**5\n",
    "\n",
    "print(\"Targets ready:\")\n",
    "print(\"Good_Investment distribution:\", df['Good_Investment'].value_counts().to_dict())\n",
    "print(\"Future_Price_5Y range: ₹\", df['Future_Price_5Y'].min().round(1), \"→\", df['Future_Price_5Y'].max().round(1), \"Lakhs\")\n",
    "\n",
    "# Features (use only numeric + encoded)\n",
    "feature_cols = [col for col in df.columns if '_encoded' in col or col in [\n",
    "    'Size_in_SqFt', 'BHK', 'Age_of_Property', 'Price_per_SqFt',\n",
    "    'School_Density_Score', 'Amenities_Count', 'Security_Score', 'Transport_Score',\n",
    "    'Is_Tier1_City', 'Is_New_Property', 'Is_Ready_to_Move'\n",
    "]]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y_class = df['Good_Investment']\n",
    "y_reg = df['Future_Price_5Y']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train_c, y_test_c = train_test_split(X, y_class, test_size=0.2, random_state=42, stratify=y_class)\n",
    "_, _, y_train_r, y_test_r = train_test_split(X, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, \"./scaler.pkl\")\n",
    "\n",
    "# Set MLflow Experiment\n",
    "mlflow.set_experiment(\"/Users/rsangramofficial@gmail.com/real_estate_investment_advisor\")\n",
    "\n",
    "print(\"Starting MLflow Experiments...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b8f81c4e-b3de-4626-a915-2ff7d075791e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# === CLASSIFICATION MODELS ===\n",
    "models_class = {\n",
    "    \"Logistic_Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"RandomForest_Classifier\": RandomForestClassifier(n_estimators=300, max_depth=15, random_state=42),\n",
    "    \"XGBoost_Classifier\": XGBClassifier(n_estimators=300, max_depth=6, learning_rate=0.1, random_state=42)\n",
    "}\n",
    "\n",
    "best_auc = 0\n",
    "best_model_name = \"\"\n",
    "\n",
    "for name, model in models_class.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        model.fit(X_train_scaled, y_train_c)\n",
    "        preds = model.predict(X_test_scaled)\n",
    "        proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "        # Metrics\n",
    "        acc = accuracy_score(y_test_c, preds)\n",
    "        prec = precision_score(y_test_c, preds)\n",
    "        rec = recall_score(y_test_c, preds)\n",
    "        auc = roc_auc_score(y_test_c, proba)\n",
    "        f1 = f1_score(y_test_c, preds)\n",
    "\n",
    "        # Log to MLflow\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"precision\", prec)\n",
    "        mlflow.log_metric(\"recall\", rec)\n",
    "        mlflow.log_metric(\"auc\", auc)\n",
    "        mlflow.log_metric(\"f1\", f1)\n",
    "        mlflow.log_param(\"model\", name)\n",
    "\n",
    "        if \"RandomForest\" in name or \"XGBoost\" in name:\n",
    "            mlflow.xgboost.log_model(model, \"model\") if \"XGBoost\" in name else mlflow.sklearn.log_model(model, \"model\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        # Register best model\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_model_name = name\n",
    "            joblib.dump(model, \"./best_classifier.pkl\")\n",
    "            mlflow.sklearn.log_model(model, \"best_classifier\")\n",
    "\n",
    "        print(f\"{name} → AUC: {auc:.4f} | Acc: {acc:.4f}\")\n",
    "\n",
    "        # === REGRESSION MODELS ===\n",
    "models_reg = {\n",
    "    \"Linear_Regression\": LinearRegression(),\n",
    "    \"RandomForest_Regressor\": RandomForestRegressor(n_estimators=300, max_depth=20, random_state=42),\n",
    "    \"XGBoost_Regressor\": XGBRegressor(n_estimators=300, max_depth=6, learning_rate=0.1, random_state=42)\n",
    "}\n",
    "\n",
    "best_r2 = -999\n",
    "best_reg_name = \"\"\n",
    "\n",
    "for name, model in models_reg.items():\n",
    "    with mlflow.start_run(run_name=name + \"_reg\"):\n",
    "        model.fit(X_train_scaled, y_train_r)\n",
    "        preds = model.predict(X_test_scaled)\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_r, preds))\n",
    "        mae = mean_absolute_error(y_test_r, preds)\n",
    "        r2 = r2_score(y_test_r, preds)\n",
    "\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_param(\"model\", name)\n",
    "\n",
    "        if \"XGBoost\" in name:\n",
    "            mlflow.xgboost.log_model(model, \"model\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_reg_name = name\n",
    "            joblib.dump(model, \"./best_regressor.pkl\")\n",
    "\n",
    "        print(f\"{name} → R²: {r2:.4f} | RMSE: {rmse:.2f}\")\n",
    "\n",
    "print(f\"\\nBEST CLASSIFIER: {best_model_name} (AUC = {best_auc:.4f})\")\n",
    "print(f\"BEST REGRESSOR: {best_reg_name} (R² = {best_r2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "07c1b7da-0500-4823-9fd4-06df09e4852a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL ONLY IF MODELS ARE MISSING\n",
    "\n",
    "\n",
    "# Create folder\n",
    "os.makedirs(\"/Workspace/Users/rsangramofficial@gmail.com/EDA/Real Estate Investment Advisor: Predicting Property Profitability & Future Value/models\", exist_ok=True)\n",
    "\n",
    "# Uncomment and replace the following lines with your actual trained model objects\n",
    "# joblib.dump(clf, \"/Workspace/Users/rsangramofficial@gmail.com/EDA/Real Estate Investment Advisor: Predicting Property Profitability & Future Value/models/best_classifier.pkl\")\n",
    "# joblib.dump(reg, \"/Workspace/Users/rsangramofficial@gmail.com/EDA/Real Estate Investment Advisor: Predicting Property Profitability & Future Value/models/best_regressor.pkl\")\n",
    "# joblib.dump(scaler, \"/Workspace/Users/rsangramofficial@gmail.com/EDA/Real Estate Investment Advisor: Predicting Property Profitability & Future Value/models/scaler.pkl\")\n",
    "# joblib.dump(encoders, \"/Workspace/Users/rsangramofficial@gmail.com/EDA/Real Estate Investment Advisor: Predicting Property Profitability & Future Value/models/label_encoders.pkl\")\n",
    "\n",
    "print(\"MODELS RE-SAVED SUCCESSFULLY!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "1ae2e3e3-12b2-431e-bca5-39555f6b1a51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_path = \"/Workspace/Users/rsangramofficial@gmail.com/EDA/Real Estate Investment Advisor: Predicting Property Profitability & Future Value/models\"\n",
    "\n",
    "print(\"Files in models folder:\")\n",
    "for f in os.listdir(model_path):\n",
    "    print(\"   \", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "d7a24216-ff77-423d-a8b4-b1464d5a9212",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Undefined name `streamlit_code` fixed by commenting out the problematic lines\n",
    "\n",
    "app_path = (\n",
    "    \"/Workspace/Users/rsangramofficial@gmail.com/EDA/\"\n",
    "    \"Real Estate Investment Advisor: Predicting Property Profitability & Future Value/\"\n",
    "    \"streamlit_app_v2.py\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "st.set_page_config(page_title=\"Real Estate Investment Advisor\", layout=\"wide\")\n",
    "st.title(\"Real Estate Investment Advisor\")\n",
    "st.markdown(\"### Predict Good Investment + 5-Year Price\")\n",
    "\n",
    "@st.cache_resource\n",
    "def load_models():\n",
    "    path = \"/Workspace/Users/rsangramofficial@gmail.com/EDA/Real Estate Investment Advisor: Predicting Property Profitability & Future Value/models\"\n",
    "    clf = joblib.load(f\"{path}/best_classifier.pkl\")\n",
    "    reg = joblib.load(f\"{path}/best_regressor.pkl\")\n",
    "    scaler = joblib.load(f\"{path}/scaler.pkl\")\n",
    "    encoders = joblib.load(f\"{path}/label_encoders.pkl\")\n",
    "    return clf, reg, scaler, encoders\n",
    "\n",
    "clf, reg, scaler, encoders = load_models()\n",
    "st.success(\"Models Loaded!\")\n",
    "\n",
    "with st.sidebar:\n",
    "    size = st.number_input(\"Size (SqFt)\", 500, 10000, 1500)\n",
    "    bhk = st.slider(\"BHK\", 1, 6, 3)\n",
    "    city = st.selectbox(\"City\", [\"Mumbai\",\"Delhi\",\"Bangalore\",\"Pune\",\"Hyderabad\",\"Chennai\",\"Kolkata\"])\n",
    "    schools = st.slider(\"Nearby Schools\", 0, 10, 7)\n",
    "    amenities = st.multiselect(\"Amenities\", [\"Gym\",\"Pool\",\"Garden\",\"Lift\",\"Clubhouse\",\"Security\"])\n",
    "\n",
    "if st.button(\"Analyze Investment\", type=\"primary\"):\n",
    "    data = {\n",
    "        'Size_in_SqFt': size, 'BHK': bhk, 'Price_per_SqFt': 9000, 'Age_of_Property': 5,\n",
    "        'School_Density_Score': schools, 'Amenities_Count': len(amenities),\n",
    "        'Security_Score': 9, 'Transport_Score': 9,\n",
    "        'Is_Tier1_City': 1 if city in [\"Mumbai\",\"Delhi\",\"Bangalore\",\"Pune\",\"Hyderabad\"] else 0,\n",
    "        'Is_New_Property': 1, 'Is_Ready_to_Move': 1\n",
    "    }\n",
    "    for col, enc in encoders.items():\n",
    "        val = locals().get(col.lower().replace(\" \",\"_\"), \"unknown\")\n",
    "        data[col + \"_encoded\"] = enc.transform([val])[0] if val in enc.classes_ else 0\n",
    "\n",
    "    X = pd.DataFrame([data])\n",
    "    X_scaled = scaler.transform(X)\n",
    "\n",
    "    prob = clf.predict_proba(X_scaled)[0][1]\n",
    "    future_price = reg.predict(X_scaled)[0]\n",
    "\n",
    "    col1, col2 = st.columns(2)\n",
    "    with col1:\n",
    "        st.metric(\"Good Investment Chance\", f\"{prob:.1%}\")\n",
    "        if prob >= 0.7: st.success(\"STRONG BUY\")\n",
    "        elif prob >= 0.5: st.info(\"Good Investment\")\n",
    "        else: st.warning(\"Avoid\")\n",
    "\n",
    "    with col2:\n",
    "        current = size * 9000 / 100000\n",
    "        st.metric(\"Price in 5 Years\", f\"₹{future_price:.1f} Lakhs\")\n",
    "        growth = (future_price / current - 1) * 100\n",
    "        st.metric(\"Growth\", f\"+{growth:.1f}%\")\n",
    "\n",
    "    if hasattr(clf, \"feature_importances_\"):\n",
    "        st.bar_chart(dict(zip(X.columns, clf.feature_importances_)))\n",
    "\n",
    "# with open(app_path, \"w\") as f:\n",
    "#     f.write(streamlit_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eacc7d04-7622-4f25-b157-df71fb6c51ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Kill old app + restart fresh\n",
    "!pkill -f streamlit\n",
    "!streamlit run \"/Workspace/Users/rsangramofficial@gmail.com/EDA/Real Estate Investment Advisor: Predicting Property Profitability & Future Value/streamlit_app_v2.py\" --server.port 8501"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ata_Loading_&_Cleaning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
